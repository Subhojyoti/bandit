	
	Here, we state the main theorem of the paper which shows the regret upper bound of ClusUCB.
	
\begin{theorem}
\label{Result:Theorem:1}
Considering both the arm elimination and cluster elimination condition and $p>1$, the total regret till $T$ is upper bounded by $R_{T}\leq \sum_{i\in A:\Delta_{i}\geq b} \bigg\lbrace 2\Delta_{i}+ \bigg(\dfrac{32}{\Delta_{i}^{3}}\bigg) + \bigg(\dfrac{2^{2+4\rho_{s}}\rho_{s}^{2\rho_{s}}T^{1-\rho_{s}}}{\Delta_{i}^{4\rho_{s}-1}}\bigg) + \bigg(\dfrac{32\log{(T\dfrac{\Delta_{i}^{4}}{16})}}{\Delta_{i}}\bigg) + \bigg(\dfrac{32\rho_{s}\log{(T\dfrac{\Delta_{i}^{4}}{16\rho_{s}^{2}})}}{\Delta_{i}}\bigg)\bigg\rbrace + \sum_{i\in A_{s^{*}}:0\leq\Delta_{i}\leq b}\bigg\lbrace \bigg(\dfrac{12}{\Delta_{i}^{3}} \bigg) + \bigg(\dfrac{12}{b^{3}} \bigg)\bigg\rbrace + \sum_{i\in A:0\leq\Delta_{i}\leq b}\bigg\lbrace \bigg(\dfrac{T^{1-\rho_{s}}\rho_{s}^{2\rho_{s}}2^{2\rho_{s}+3}}{\Delta_{i}^{4\rho_{s}-1}} \bigg)+\bigg(\dfrac{T^{1-\rho_{s}}\rho_{s}^{2\rho_{s}}2^{2\rho_{s}+3}}{b^{4\rho_{s} -1}} \bigg) \bigg\rbrace + max_{i:\Delta_{i}\leq b}\Delta_{i}T $, where $\rho_{s}\in (0,1]$ is the cluster elimination parameter, $A_{s^{*}}$ is the number of arms in optimal cluster $s^{*}$ such that $|A_{s^{*}}|\leq \big\lceil\frac{K}{p}\big\rceil$ , $p$ is the number of clusters and $T$ is the horizon.
\end{theorem}

\begin{proof}
	The proof of this is given in \textbf{Appendix C}.(Supplementary Material)
\end{proof}

\begin{remark}
\label{Result:Rem:1}
By setting $b=\sqrt{\dfrac{e}{T}}$, the term $max_{i:\Delta_{i}\leq b}\Delta_{i}T$ gets trivially bounded by $\sqrt{KT}$ as mentioned in UCB-Improved.
%which makes the logarithmic term  the main term for suitable $b$
\end{remark}

\begin{remark}
\label{Result:Rem:2}
From the statement of Theorem $1$ we can see that taking various values of $\rho_{s}$ and $\rho_{a}$ and how these values are reduced after every round significantly affects our regret bound.A discussion on them is deferred to \textbf{Remark \ref{App:A:Rem:1}, Appendix A}, \textbf{Remark \ref{App:B:Rem:2},\ref{App:B:Rem:3}, Appendix B} and \textbf{Remark \ref{App:E:Rem:2}, Appendix E} and its various definitions are given in \textbf{Appendix E}. A discussion on exploration regulatory factor($\psi_{m}$) and its effect is deferred to \textbf{Appendix D}. In the analysis of proof(\textbf{Remark \ref{Result:Rem:3}-\ref{Result:Rem:7}}) we will use both $\psi_{m}$ and $\rho_{s}$. The full regret bound which includes the factors $\rho_{s},\rho_{a}$ and $\psi_{m}$ can be found in \textbf{Remark \ref{App:D:Rem:1}, Appendix D}.
\end{remark}

\begin{remark}
\label{Result:Rem:3}
So, for the term $\sum_{i\in A:\Delta_{i}\geq b}\dfrac{32\rho_{s}\log{(\psi_{m}T\dfrac{\Delta_{i}^{4}}{16\rho_{s}^{2}})}}{\Delta_{i}}$ by setting $b\approx \sqrt{\dfrac{K\log K}{T}}$ in the term we get, $K\dfrac{32\rho_{s}\log{(\psi_{m}T\dfrac{K^{2}(\log K)^{2}}{16\rho_{s}^{2}T^{2}})}}{\sqrt{\dfrac{K\log K}{T}}}=\dfrac{32K\sqrt{T}\rho_{s}\log{(\psi_{m}\dfrac{K^{2}(\log K)^{2}}{16\rho_{s}^{2}T})}}{ \sqrt{K\log K}}$. Again, since there are $\big \lfloor \dfrac{1}{2}\log_{2} \dfrac{T}{e}\big\rfloor$ rounds then $\rho_{s}\geq \dfrac{1}{4}$(from Definition $2$, \textbf{Appendix E}) and taking $\psi_{m}=K^{2}T$(from Definition $3$, \textbf{Appendix D}). So we get, $\dfrac{32\sqrt{KT}\log{(16\dfrac{K^{4}(\log K)^{2}}{16*T})}}{4\sqrt{\log K}} \leq \dfrac{8\sqrt{KT}\log{(\dfrac{K^{4}(\log K)^{2}}{T})}}{\sqrt{\log K}}$.
\end{remark}

%Since $T>> K$, so this essentially becomes better than UCB-Improved non-gap based regret upper bound of $\sqrt{KT}\dfrac{\log(K\log K)}{\sqrt{\log K}}$. Also, comparing to the MOSS bound of $\sqrt{KT}$, our bound essentially is better than MOSS.

%\begin{remark}
%So, the most significant part of the regret bound is $\sum_{i\in A}\dfrac{32(K+p)\rho_{s}\log{(T\dfrac{\Delta_{i}^{4}}{16\rho_{s}^{2}})}}{p\Delta_{i}}$. For $b\approx \sqrt{\dfrac{K\log K}{T}}$ in the term we get, $K\dfrac{(K+p)\rho_{s}\log{(T\dfrac{K^{2}(\log K)^{2}}{\rho_{s}^{2}T^{2}})}}{p \sqrt{\dfrac{K\log K}{T}}}=\dfrac{K(K+p)\sqrt{T}\rho_{s}\log{(\dfrac{K^{2}(\log K)^{2}}{\rho_{s}^{2}T})}}{p \sqrt{K\log K}}$. Now for $p\leq \dfrac{K}{2}$(considering each cluster gets atleast $2$ arms) we get $\dfrac{(K+p)}{p}\leq  2$. Again, since there are $\big \lfloor \dfrac{1}{2}\log_{2} \dfrac{T}{e}\big\rfloor$ rounds then $\rho_{s}\leq \dfrac{1}{K^{2}}$(from Definition $2$, \textbf{Appendix E}). So we get, $\dfrac{\sqrt{KT}\log{(\dfrac{K^{6}(\log K)^{2}}{T})}}{K^{2}\sqrt{\log K}}=\dfrac{\sqrt{TK}\log{(\dfrac{K^{6}(\log K)^{2}}{T})}}{K^{2}\sqrt{\log K}}$. Since $T>> K$, so $\dfrac{\log{(\dfrac{K^{6}(\log K)^{2}}{T})}}{K^{2}\sqrt{\log K}} < \dfrac{\log (K\log K)}{\sqrt{\log K}}$ and so our bound essentially becomes better than UCB-Improved non-gap based regret upper bound of $\sqrt{KT}\dfrac{\log(K\log K)}{\sqrt{\log K}}$. Also, comparing to the MOSS bound of $\sqrt{KT}$, our bound essentially is better than MOSS when $\dfrac{\log{(\dfrac{K^{6}(\log K)^{2}}{T})}}{K^{2}\sqrt{\log K}}$.
%\end{remark}

\begin{remark}
\label{Result:Rem:4}
Again, of the several terms in the regret bound, the terms like  $\sum_{i\in A:0\leq\Delta_{i}\leq b}\bigg(\dfrac{T^{1-\rho_{s}}\rho_{s}^{2\rho_{s}}2^{2\rho_{s}+3}}{\psi_{m}^{\rho_{s}}\Delta_{i}^{4\rho_{s}-1}} \bigg)$ can become very large given a small $\Delta_{i}$ and large $T$. Drawing from the conclusion of our exploration regulatory factor in \textbf{Appendix D}, we can introduce $\psi_{m}=K^{2}T$ in our confidence interval thereby when $\rho_{s}=\dfrac{1}{4}$(from Definition $2$, \textbf{Appendix E}) then the term essentially becomes $K\bigg(\dfrac{T^{\frac{3}{4}}(\frac{1}{4})^{\frac{1}{2}}2^{\frac{1}{2}+3}}{{(K^{2}T})^{\frac{1}{4}}{(\Delta_{i})^{4*\frac{1}{4}-1}}} \bigg) = 5.6\sqrt{KT}$. A similar result can also be shown for $\sum_{i\in A:0\leq\Delta_{i}\leq b}\bigg(\dfrac{T^{1-\rho_{s}}\rho_{s}^{2\rho_{s}}2^{2\rho_{s}+3}}{b^{4\rho_{s} -1}} \bigg)=5.6\sqrt{KT}$ and $\sum_{i\in A:\Delta_{i}\geq b}\bigg(\dfrac{T^{1-\rho_{s}}\rho_{s}^{2\rho_{s}}2^{2+4\rho_{s}}}{\psi_{m}^{\rho_{s}}\Delta_{i}^{4\rho_{s}-1}} \bigg)=4\sqrt{KT}$. 
\end{remark}

\begin{remark}
\label{Result:Rem:5}
So, we see that putting $b=\sqrt{\dfrac{K\log K}{T}}$, the corresponding terms of $\rho_{s}$ and $\psi_{m}$ and then combining \textbf{remark \ref{Result:Rem:3} and \ref{Result:Rem:4}} we get $\dfrac{8\sqrt{KT}\log{(\dfrac{K^{4}(\log K)^{2}}{T})}}{\sqrt{\log K}} + 15.2\sqrt{KT}$. Now, the worst case gap-independent regret bound of $\bigg\lbrace \dfrac{\sqrt{KT}\log{(\dfrac{K^{4}(\log K)^{2}}{T})}}{\sqrt{\log K}}\bigg\rbrace$ which coincides with the term $bT$ of the regret bound in \textbf{Theorem 1}, except the term  $\dfrac{\log{(\dfrac{K^{4}(\log K)^{2}}{T})}}{\sqrt{\log K}}$. When we consider that $T\approx K^{4}(\log K)^{2}$, this term becomes negligible and so the regret bound becomes better than UCB-Improved non-gap based regret upper bound of $\sqrt{KT}\dfrac{\log(K\log K)}{\sqrt{\log K}}$ and slightly better than the MOSS bound of $49\sqrt{KT}$. This shows that for large number of arms $K$ and moderately high time horizon $T$ we have a very strong regret guarantee.
\end{remark}

\begin{remark}
\label{Result:Rem:6}
A similar result can be shown for the term $\dfrac{32\rho_{a}\log{(\psi_{m}T\dfrac{\Delta_{i}^{4}}{16\rho_{a}^{2}})}}{\Delta_{i}}$ and for the terms like $\bigg(\dfrac{T^{1-\rho_{a}}\rho_{a}^{2\rho_{a}}2^{2\rho_{a}+\frac{3}{2}}}{\psi_{m}^{\rho_{a}}\Delta_{i}^{4\rho_{a}-1}} \bigg)$ which come from Arm Elimination method. A clear distinction between using only arm elimination method(as proved in \textbf{Proposition 1}) or using only cluster elimination method(as proved in \textbf{Proposition 2}) or both arm and cluster elimination(as proved in \textbf{Theorem 1}) is shown in \textbf{Remark \ref{App:E:Rem:2}}.
\end{remark}

%At the same time putting $\psi_{m}=\sqrt{T}$ in the term $\sum_{i\in A}\dfrac{32(K+p)\rho_{s}\log{(\psi_{m}T\dfrac{\Delta_{i}^{4}}{16\rho_{s}^{2}})}}{p\Delta_{i}}$ and taking $b\approx \sqrt{\dfrac{K\log K}{T}}$ we get by the same way as above a worst case regret bound of $\dfrac{\sqrt{eK}\log{(\sqrt{T}\dfrac{K^{2}(\log K)^{2}}{e})}}{\sqrt{\log K}}$. This is still less than the worst case of MOSS and UCB-Improved.

\begin{remark}
\label{Result:Rem:7}
	When we consider gap-dependent bound, by choosing appropriate values of $\rho_{s},\psi_{m}$ and $p$ we see that the most significant term in the regret is $\sum_{i\in A:\Delta_{i}\geq b}\dfrac{32\rho_{s}\log{(\psi_{m}T\dfrac{\Delta_{i}^{4}}{16\rho_{s}^{2}})}}{\Delta_{i}}= \dfrac{8K\log{(T\log T\dfrac{\Delta_{i}^{4}}{32})}}{\Delta_{i}}$ (when $\rho_{s} \geq \frac{1}{4}$ and $\psi_{m}=\dfrac{\log T}{2^{m}}$), which is significantly lower than UCB1, MOSS and UCB-Improved. A table for the various regret upper bounds is given in \textbf{Appendix F}. From the \textbf{Remarks \ref{Result:Rem:3}-\ref{Result:Rem:6}} we see that $\rho_{s}$ actually helps in reducing the constant associated with the factor $\sqrt{KT}$ and the $\dfrac{\log(\psi_{m}\dfrac{T\Delta_{i}^{4}}{\rho_{s}^{2}})}{\Delta_{i}}$ term and also both $\psi_{m}$ and $\rho_{s}$ helps in stabilizing the term $\log(\psi_{m}\dfrac{T\Delta_{i}^{4}}{\rho_{s}^{2}})$.
	
%Also ClusUCB is more efficient than UCB1, MOSS, KL-UCB as $K$ scales up because being a round-based algorithm, it is removing sub-optimal arms in each round as opposed to the former algorithms which are calculating the confidence bounds over all arms in each timestep and then choosing the max of them. Also it is better than UCB-Improved and Median Elimination because of the aggressive elimination condition as showed in proposition 2 which leads to lower expected regret but at a higher risk.
%Also evident from the proof is that if the horizon $T$ is small or very large we can tune the parameter $\psi_{m}$ carefully to have a lesser regret. For readers convenience a table is given in Appendix G on the various regret bounds of several algorithms. 
\end{remark}	

%\todos{(Subho)To follow the same way as UCB-Revisited proof, did away with the event $\xi_{1},\xi_{2},\xi_{3}$}

%In this section we will prove the bounds based on the events $\xi_{1}$,$\xi_{2}$ and $\xi_{3}$. In $\xi_{1}$, we will assume two important assumptions $i)\hat{r}^{*}<\hat{r}_{i},\forall i\in s_{i}$ and $ii)\exists a_{i}\in s_{i}$ such that $\sqrt{\dfrac{\epsilon_{m}}{w_{s_{i}}}}<\dfrac{\Delta_{i}}{5}$. For $\xi_{2}$, we will assume that $a^{*}\in s^{*}$ and $|s^{*}|=1$, $a_{i}\in s_{i} \forall a_{i}\setminus a^{*}\in B_{m}$ and $\exists a_{max_{s_{i}}}$ such that $\sqrt{\epsilon_{m}}<\dfrac{2\Delta_{s}}{5}$, where $\Delta_{s}=r^{*}-r_{max_{s_{i}}}$ and $\hat{r}_{max_{s_{i}}}>\hat{r}_{i}, \forall i\in s_{i}$. $\xi_{3}$ be the event when the optimal arm $a^{*}$ gets eliminated by a sub-optimal arm. At the start of any round $m$, we fix $\epsilon_{m}$.

\begin{remark}
\label{Result:Rem:8}
In the experimental setup we use $\psi_{m}$ as stated in \textbf{Appendix D, Definition 4} and $\rho_{s}$ and $\rho_{a}$ as stated in \textbf{Appendix E, Definition 5}.
%The corresponding bound can be found in \textbf{Remark \ref{App:E:Rem:1}}.
\end{remark}

\begin{remark}
\label{Result:Rem:9}
A sketch of the proof for \textbf{Theorem $1$} is given here. In the \textbf{first step}, we try to bound the probability of arm elimination of any sub-optimal arm without cluster elimination. This is shown in Proposition $1$. By simply taking $p=1$ we can achieve arm elimination without any cluster elimination. In second step, we try to bound the probability of cluster elimination(without any arm elimination) with all arms within it.  A slight modification to the algorithm allows us to do this. By taking $p>1$, removing the arm elimination condition, stopping when we are just left with one cluster and pulling the $max\lbrace \hat{r}_{i}\rbrace$, where $a_{i}\in B_{m}$ we can achieve this.  This is shown in Proposition $2$. Finally, in the proof of Theorem 1 we combine both arm elimination and cluster elimination to get the regret upper bound.  
\end{remark}
	
%\begin{proposition}
%The probability that the optimal arm $a^{*}\in s_{i}$ will lie above $\hat{r}_{min_{s_{i}}}+ \dfrac{\hat{\Delta}_{s_{i}}}{2}$ after $\bigg\lceil\dfrac{2\log (\psi_{m}T\epsilon_{m}^{2})}{\epsilon_{m}}\bigg\rceil$ pulls in the $m$-th round is given by $\bigg\lbrace 1- \dfrac{1}{(\psi_{m}T\epsilon_{m}^{2})^{\ell_{m}^{2}\epsilon_{m}}} \bigg\rbrace$ where $\hat{r}_{min_{s_{i}}}$ is the minimum payoff in $s_{i}$, $\hat{\Delta}_{s_{i}}=max_{i\in s_{i}}\hat{r}_{i}-min_{j\in s_{i}}\hat{r}_{j}, i\neq j$, $\epsilon_{m}$ is halved after every round and $T$ is the horizon. 
%\end{proposition}

%$\epsilon_{m}=\max{\bigg\lbrace\dfrac{\hat{\Delta}_{m}}{\ell_{m}} \dfrac{2}{\sqrt{\psi{(m)T}}}\bigg\rbrace}$

%The proof of Proposition 1 is given in \textbf{Appendix A}.(Supplementary material)

%\begin{remark}
%	Thus, we see that as the agent falls through rounds, with increasing values of $\ell_{m}$ the probability of optimal arm $a^{*}$ lying above $\dfrac{\hat{\Delta}_{s_{i}}}{2}$ increases as $\ell_{m}^{2}\epsilon_{m}\geq 4$ (as, $\epsilon_{m}$ is halved after every round and $\ell_{m}$ is doubled) increases with increasing $\ell_{m}$. But, $\ell_{m}$ is bounded by $D_{m}$ and say after the $m_{D}$ round the probability of optimal arm staying above the specified range gets bounded by $\bigg\lbrace 1- \dfrac{1}{(\psi_{m}T\epsilon_{m}^{2})^{D_{m}^{2}\epsilon_{m}}} \bigg\rbrace$. But we know from the definition of $D_{m}$ that $ D_{m}=\bigg\lceil(\dfrac{1}{\epsilon_{m}})^{1/2}\bigg\rceil$ or $D^{2}\epsilon_{m}\approx 1$. Hence, the probability that   $a^{*}$ after $n_{m}$ pulls in round $m_{D}$ going above $\dfrac{\hat{\Delta}_{s_{i}}}{2}$ is $\bigg\lbrace 1- \dfrac{1}{(\psi_{m}T\epsilon_{m}^{2}) }\bigg\rbrace$.

%	We must also point out that $\epsilon_{m}$ can become arbitrarily small, so the value $\log{(\psi{(m)}T\epsilon_{m}^{2})}$ can become negative. To guard against that scenario we have setup a tolerance level such as $\epsilon_{m}>\dfrac{2}{\sqrt{\psi{(m)}T}}$ and below this value $\epsilon_{m}$ should not be allowed to fall. 
%	We also see that $\ell_{m}$ is doubled after every round, independent of the rise in $D_{m}$ and as $\epsilon_{m}\rightarrow \Delta $, $\ell_{m}$ gets upper bounded by $D_{m}$ and will rise no more and hence $D_{m}$ also gets fixed as $D_{m}^{2}\epsilon_{m}\approx 1$ for any round $m$. We make the $D_{m}$ increase with the rounds as it controls our rate of exploration and in the later rounds we need more exploration as arms close to the optimal arm will survive till the later rounds and the algorithm needs to discriminate amongst them.  Also, if $\epsilon_{m}$ is very large, then $D_{m}$ becomes very small and consequently there is very small exploration. Hence, $D_{m}$ is the maximum of $\lbrace \dfrac{1}{\sqrt{\epsilon_{m}}}, K \rbrace$, which ensures the algorithm does sufficient exploration. 
%\end{remark}


%\todos{(Subho) Merged proposition 2 and 3 into one to follow the UCB-Revisited case (a)}

\begin{proposition}
\label{Result:Prop:1}
Considering only the arm elimination condition and $\rho_{a}=1$ and $p=1$ the total regret till $T$ is upper bounded by $R_{T}\leq \sum_{i\in A:\Delta_{i}\geq b}\bigg \lbrace \bigg(\dfrac{44}{(\Delta_{i})^{3}}\bigg) + \bigg(\Delta_{i}+\dfrac{32\log{(T\dfrac{\Delta_{i}^{4}}{16})}}{\Delta_{i}}\bigg)\bigg\rbrace + \sum_{i\in A:0\leq\Delta_{i}\leq b}\dfrac{12}{b^{3}} + max_{i:\Delta_{i}\leq b}\Delta_{i}T$ for all $b\geq\sqrt{\dfrac{e}{T}}$, where $\rho_{a}$ is the arm elimination parameter, $p$ is the number of clusters and $T$ is the horizon.
\end{proposition}

	The proof of Proposition 1 is given in \textbf{Appendix A}.(Supplementary material).

\begin{remark}
\label{Result:Rem:10}	
	Thus, we see that the confidence interval term $c_{m}=\sqrt{\dfrac{\log (T\epsilon_{m}^{2})}{2 n_{m}}}$ makes the algorithm eliminate an arm $a_{i}$ as soon as $\sqrt{\epsilon_{m}}<\dfrac{\Delta_{i}}{2}$. The above result is in contrast with UCB-Improved which only deletes an arm if $\tilde{\Delta}_{m}<\dfrac{\Delta_{i}}{2}$, where $\tilde{\Delta}_{m}$ is initialized at $1$ and is halved after every round. We can also point out out here intuitively that when $c_{m}=\sqrt{\dfrac{\rho_{a}\log (T\epsilon_{m}^{2})}{2 n_{m}}}$ and $\rho_{a}$ is decreased after every round, then an arbitrary arm $a_{i}$ is removed as soon as  $\sqrt{\rho_{a}\epsilon_{m}}<\dfrac{\Delta_{i}}{2}$ which essentially makes it a faster elimination procedure than UCB-Improved if $\rho_{a}\leq \epsilon_{m}$. The proof of a similar approach regarding cluster elimination is shown in proposition 2.
\end{remark}

%Also, the weight $w_{s_{i}}$ as shown in the proofs actually help us in faster elimination of arms by the condition $ii$ in $\xi_{1}$ explained at the start of the proof. The higher the weight faster is arm elimination but it also increases error probability which might actually lead to a higher cumulative regret. The weight $w_{s_{i}}$ depends on the cluster size and the larger the cluster size, the higher will be the weight increasing the probability of arm elimination as we want smaller and smaller number of elements in clusters so that we can discriminate effectively amongst the clusters.
%\end{remark}
%
%
%\begin{proposition}
%With a probability of $\bigg\lbrace 1-\bigg(\dfrac{2}{\psi_{m}T\epsilon_{m}^{2})}\bigg)\bigg\rbrace$ a sub-optimal arm can be deleted within a cluster $s_{i}$ in round $m$ by the arm elimination condition, where $\epsilon_{m}=\max{\bigg\lbrace\dfrac{\hat{\Delta}_{s,m}}{\ell_{m}}, \dfrac{1}{\sqrt{\psi{(m)T}}}\bigg\rbrace}$, if $\hat{\Delta}_{s,m}\neq 0$ and $T$ is the horizon.
%\end{proposition}
%
%	The proof of Proposition 3 is given in \textbf{Appendix C}.(Supplementary material)	
%
%\begin{remark}
%	Thus, we see that the probability of a sub-optimal arm $a_{i}$ is eliminated in $\xi_{1}$ is  $\bigg(1-\dfrac{2}{\psi_{m}T\epsilon_{m}^{2})}\bigg)$ which increases as the algorithm falls through the round as $\epsilon_{m}$ keeps on decreasing.
%	
%	Due to the initial uncertainty we can sufficiently tune $\psi_{m}$ to increase our pulls in the initial rounds in a bounded fashion. But this function can be set arbitrarily high resulting in a skewed regret upper bound and so we need to define a structure and bound this function as well. We define $\psi_{m}=\dfrac{c}{m}$ where $c>0, m\geq 1$ as defined previously. Notice also that $\psi_{m}$ is a monotonically decreasing function and for any round $m$, $|\psi(m+1)|\leq |\psi_{m}|$. 
%%In experiment 2 and 3 where $\psi_{m}=K^{5/m}$ is defined since the variance is very high in those cases. 
%%Since $|\psi_{m}|\geq 0,\forall m$, this also leads to increase in the probability of arm deletion as compared to UCB-Revisited.
%When the time horizon $T$ is very large or very small, as the pulls $n_{m}$ depends on $T$, we can tune $\psi_{m}$ by changing $c$ so that the exploration remains balanced. Since we are exploring locally and the pulls are increasing after every round so we decrease $\psi_{m}$ in the later rounds which not only tapers down the growth of $n_{m}$ but also decreases arm elimination probability, as in the later rounds, only arms closer to the optimal arm survive and we need careful elimination.

	
	
	

\begin{proposition}
\label{Result:Prop:2}
Considering only the cluster elimination condition and $p>1$, the total regret till $T$ is upper bounded by $R_{T}\leq \sum_{i\in A:\Delta_{i}\geq b}\bigg\lbrace \bigg(\dfrac{2^{2+4\rho_{s}}\rho_{s}^{2\rho_{s}}T^{1-\rho_{s}}}{\Delta_{i}^{4\rho_{s}-1}}\bigg) + \bigg(\Delta_{i}+\dfrac{32\rho_{s}\log{(T\dfrac{\Delta_{i}^{4}}{16\rho_{s}^{2}})}}{\Delta_{i}}\bigg)  +  \bigg(\dfrac{T^{1-\rho_{s}}\rho_{s}^{2\rho_{s}}2^{2\rho_{s}+3}}{\Delta_{i}^{4\rho_{s} -1}} \bigg)\bigg \rbrace +\sum_{i\in A:0\leq\Delta_{i}\leq b}\bigg(\dfrac{T^{1-\rho_{s}}\rho_{s}^{2\rho_{s}}2^{2\rho_{s}+3}}{b^{4\rho_{s} -1}} \bigg) + max_{i:\Delta_{i}\leq b}\Delta_{i}T$ for all $b\geq \sqrt{\dfrac{e}{T}}$, where $\rho_{s}\in (0,1]$ is the cluster elimination parameter, $p$ is the number of clusters and $T$ is the horizon.
\end{proposition}

	The proof of Proposition 2 is given in \textbf{Appendix B}.(Supplementary material)


%\todos{(Subho) Have to re-write the remark once this proposition is proved}

%\begin{remark}
%	Thus, from proposition $3$ we see that the cluster deletion condition is more aggressive than arm elimination condition. This is because, for cluster elimination the condition depends on the number of arms surviving till $m$-th round that is $|B_{m}|$ which itself depends on the pulls $n_{m}$ and cluster size limit $D_{m}$. We also point out that at any round $m$ there will be $|S|$ arm elimination conditions because each cluster has its own arm elimination condition weighted by $w_{s_{i}}$, resulting in the probability of $\max{\bigg\lbrace \bigg(\dfrac{2}{\psi_{m}T\epsilon_{m}^{2})}\bigg) ,\bigg(\dfrac{4}{(\psi_{m}T\epsilon_{m}^{2})^{1+|B_{m}|^{2}\epsilon_{m}}}\bigg)\bigg\rbrace}$ of being eliminated, an increase over UCB-Revisited and Median Elimination. This is because each arm can either be eliminated by the the arm elimination condition within a cluster or by the cluster elimination condition whereby all the arms within a cluster are eliminated. Also, we 
%see that lower bounding $\epsilon_{m}=\dfrac{2}{\sqrt{\psi_{m}T}}$, lower bounds the probability of arm elimination atleast $0.5$ in $\xi_{1}$ and in $\xi_{2}$ the probability of cluster elimination and stopping very close to $1$.
%\end{remark}

%\begin{theorem}
%The upper bound on the total regret over horizon $T$ after round $m$ is given by $R_{T}\leq \sum_{i\in B_{m}}\bigg (\max{\bigg\lbrace \bigg(\dfrac{27}{\psi_{m}(\Delta_{i})^{\frac{3}{5}}}\bigg) ,\bigg(\dfrac{25\Delta_{i}}{(\psi_{m}\Delta^{2})(0.16\psi_{m}T\Delta^{2})^{2|B_{m}|^{2}\Delta/5}}\bigg)\bigg\rbrace} + \bigg(\Delta_{i}+\dfrac{27\log{(\psi_{m}T\dfrac{\Delta_{i}^{\frac{8}{5}}}{12})}}{\Delta_{i}^{\frac{3}{5}}}\bigg)\bigg)$, where $B_{m}$ is the set of arms still not eliminated in the $m$-th round and $\Delta$ is the minimal gap.
%\end{theorem}

%First level headings are all caps, flush left, bold and in point size
%12. One line space before the first level heading and 1/2~line space
%after the first level heading.

%\subsection{Error Bound}
%	
%	In this section, we try to come up with an error bound for the algorithm if at any round $m$, the optimal arm $a^{*}$ gets eliminated by another sub-optimal arm. Since, arm elimination condition is the more aggressive elimination condition, we come up with an error bound that bounds the regret once the  optimal arm gets eliminated by another sub-optimal arm. The proof of this directly follows from \textbf{Theorem 1}, and mimics the proof as in \cite{auer2010ucb}.
%	
%\begin{theorem}
%The error bound till round $m$ is given by $e_{t}\leq \sum_{i\in A^{'}}\bigg(\dfrac{51}{\psi_{m}\Delta_{i}^{6/5}} \bigg)+\sum_{i\in A^{''}\setminus A^{'}}\bigg(\dfrac{51}{\psi_{m}\Delta_{b}^{6/5}} \bigg)$, where the arms surviving till $m$-th round belong to the set $A^{'}$, arms to still survive and eliminate arm $a^{*}$ after round $m$ belong to $A^{''}$.
%\end{theorem}
%The proof of Theorem 2 is given in \textbf{Appendix F}.(Supplementary material)
%~\ref{App:B}.
