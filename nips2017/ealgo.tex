%%%%%%%%%%%%%%%% alg-custom-block %%%%%%%%%%%%
%\algblock{ArmElim}{EndArmElim}
%\algnewcommand\algorithmicArmElim{\textbf{\em Arm Elimination}}
% \algnewcommand\algorithmicendArmElim{}
%\algrenewtext{ArmElim}[1]{\algorithmicArmElim\ #1}
%\algrenewtext{EndArmElim}{\algorithmicendArmElim}
%
%\algblock{ClusElim}{EndClusElim}
%\algnewcommand\algorithmicClusElim{\textbf{\em Cluster Elimination}}
% \algnewcommand\algorithmicendClusElim{}
%\algrenewtext{ClusElim}[1]{\algorithmicClusElim\ #1}
%\algrenewtext{EndClusElim}{\algorithmicendClusElim}
%\algtext*{EndArmElim}
%\algtext*{EndClusElim}
%
%\algblock{ResParam}{EndResParam}
%\algnewcommand\algorithmicResParam{\textbf{\em Reset Parameters}}
% \algnewcommand\algorithmicendResParam{}
%\algrenewtext{ResParam}[1]{\algorithmicResParam\ #1}
%\algrenewtext{EndResParam}{\algorithmicendResParam}

\begin{algorithm}[!h]
\caption{EClusUCB}
\label{alg:eclusucb}
\begin{algorithmic}
\State {\bf Input:} Number of clusters $p$, time horizon $T$, exploration parameters $\rho_a$, $\rho_s$ and $\psi$.
\State {\bf Initialization:} Set $m:=0$, $B_{0}:=A$, $S_0 = S$, $\epsilon_{0}:=1$, $M=\big \lfloor \frac{1}{2}\log_{2} \frac{T}{e}\big\rfloor$, $n_{0}=\bigg\lceil\frac{\log{(\psi T\epsilon_{0}^{2})}}{2\epsilon_{0}}\bigg\rceil$ and  $N_{0}=Kn_{0}$.
\State Create a partition $S_0$ of the arms at random into $p$ clusters of size up to $\ell=\bigg\lceil \frac{K}{p} \bigg\rceil$ each.
\State Pull each arm once
\For{$t=K+1,..,T$}	
\State Pull arm $i\in \argmax_{j\in B_{m}}\bigg\lbrace \hat{r}_{j} + \sqrt{\frac{\log{(\psi T\epsilon_{m})}}{ z_{j}}} \bigg\rbrace$, where $z_j$ is the number of times arm $j$ has been pulled
%\State $t:=t+1$
\ArmElim
\State For each cluster $s_k \in S_{m}$, delete arm ${i}\in s_{k}$ from $B_{m}$ if
\begin{align*}
\hat{r}_{i} + \sqrt{\frac{\rho_{a}\log{(\psi T\epsilon_{m})}}{2 z_{i}}}  < \max_{{j}\in s_{k}}\bigg\lbrace\hat{r}_{j} -\sqrt{\frac{\rho_{a}\log{(\psi T\epsilon_{m})}}{2 z_{j}}} \bigg\rbrace
\end{align*}
% where $\rho_{a}=\frac{1}{w_{m}}$ and remove all such arms from $B_{m}$.
\EndArmElim
\ClusElim
\State Delete cluster $s_{k}\in S_{m}$ and remove all arms $i\in s_{k}$ from $B_{m}$ if 
\begin{align*}
 \max_{{i}\in s_{k}}\left\lbrace\hat{r}_{i} + \sqrt{\frac{\rho_{s}\log{(\psi T\epsilon_{m})}}{2 z_{i}}}\right\rbrace 
 < \max_{{j}\in B_{m}} \left\lbrace\hat{r}_{j} - \sqrt{\frac{\rho_{s} \log{(\psi T\epsilon_{m}})}{2 z_{j}}}\right\rbrace.
\end{align*}
%  and remove all such arms in the cluster $s_{k}$ from $B_{m}$ to obtain $B_{m+1}$.
\EndClusElim

\If{$t\geq N_{m}$ and $m\leq M$}
\ResParam
\State $\epsilon_{m+1}:=\frac{\epsilon_{m}}{2}$\vspace{0.5ex}
\State $B_{m+1}:=B_{m}$
\State $n_{m+1}:=\bigg\lceil\frac{\log{(\psi T\epsilon_{m+1}^{2})}}{2\epsilon_{m+1}}\bigg\rceil$
\State $N_{m+1}:=t+|B_{m+1}| n_{m+1}$
\State $m:=m+1$
\EndResParam
\State Stop if $|B_{m}|=1$ and pull ${i}\in B_{m}$ till $T$ is reached.
\EndIf
\EndFor
\end{algorithmic}
%\vspace*{-0.42em}
\end{algorithm}
%\vspace*{-0.42em}
%\textbf{2.1 Notations:} We denote the set of arms by $A$, with the individual arms labeled $i, i=1,\ldots,K$. We denote an arbitrary round of EClusUCB by $m$. We denote an arbitrary cluster by $s_{k}$, the subset of arms within the cluster $s_k$ by  $A_{s_{k}}$ and the set of clusters by $S$ with $|S|=p\leq K$. Here $p$ is a pre-specified limit for the number of clusters.
%For simplicity, we assume that the optimal arm is unique and denote it by ${*}$, with $s^{*}$ denoting the corresponding cluster. The true best arm in a cluster $s_{k}$ is denoted by $a_{max_{s_{k}}}$.  
%We denote the sample mean of the rewards seen so far for arm $i$ by $\hat{r_i}$ and for the true best arm within a cluster $s_k$ by $\hat{r}_{a_{\max_{s_{k}}}}$. $z_i$ is the number of times an arm $i$ has been pulled. We assume the rewards of all arms are bounded in $[0,1]$.

%\textbf{2.2 The algorithm.} As mentioned in a recent work \cite{liu2016modification}, UCB-Improved has two shortcomings: 	\\
%\begin{inparaenum}[\bfseries(i)]
%\item A significant number of pulls are spent in early exploration, since each round $m$ of UCB-Improved involves pulling every arm an identical $n_{m}=\left\lceil \frac{ 2\log(T\epsilon^{2}_{m})}{\epsilon^{2}_{m}} \right\rceil$ number of times. The quantity $\epsilon_{m}$ is initialized to $1$ and halved after every round.\\
%\item In UCB-Improved, arms are eliminated conservatively, i.e, only after $\epsilon_{m}<\frac{\Delta_{i}}{2}$, the sub-optimal arm $i$ is discarded with high probability. This is disadvantageous when $K$ is large and the gaps are identical ($r_{1}=r_{2}=\cdots=r_{K-1}<r^{*}$) and small.\\
%\end{inparaenum}
%To reduce early exploration, the number of pulls $n_m$ allocated to each arm per round in EClusUCB is lower than that of UCB-Improved and also that of Median-Elimination, which used $n_m=\frac{4}{\epsilon^{2}}\log\big(\frac{3}{\delta}\big)$, where $\epsilon,\delta$ are confidence parameters.
%To handle the second problem mentioned above, EClusUCB partitions the larger problem into several small sub-problems using clustering and then performs local exploration aggressively to eliminate sub-optimal arms within each clusters with high probability.

\textbf{The algorithm (EClusUCB):} One of the principal problems suffered by ClusUCB is that in every round it pulls all the arms equal number of time. EClusUCB remedies this by implementing optimistic greedy sampling, as done for CCB algorithm (see \cite{liu2016modification}. As described in the pseudocode in Algorithm~\ref{alg:eclusucb}, EClusUCB is almost similar to ClusUCB. It starts with an initial uniform  clustering of arms and the total number of rounds, $m=0,1,2,\ldots, M$ is also same. Each round of EClusUCB consists a total of $|B_m|n_m$ timesteps and parameters are updated at the end of each round. The exploration parameters are also same for both the algorithms. The first major difference with ClusUCB is that because of optimistic greedy sampling, EClusUCB only pulls the arm that has the highest confidence interval at every timestep. Also EClusUCB conducts both individual arm as well as cluster elimination conditions at every timestep. 

%These elimination conditions are inspired by UCB-Improved. Notice that, unlike UCB-Improved, there is no longer a single point of reference based on which we are eliminating arms. Instead we now have as many reference points to eliminate arms as number of clusters formed. 
%Further, the exploration factors $\rho_{a}\in (0,1]$ and $\rho_{s}\in (0,1]$ governing the arm and cluster elimination conditions, respectively, are relatively more aggressive than that in UCB-Improved. 
%In EClusUCB we also introduce the idea of optimistic greedy sampling similar to \citet{liu2016modification} which they used to modify the UCB-Improved algorithm. In optimistic greedy sampling, we only sample the arm with the highest upper confidence bound in each timestep. We further modify the idea by introducing clustering and arm elimination parameters. EClusUCB checks arm and cluster elimination conditions in every timestep and update parameters when a round is complete. It divides each round into $|B_{m}|n_{m}$ timesteps so that each surviving arms can be allocated atmost $n_{m}$ pulls. The exploration regulatory factor $\psi$ governing the arm and cluster elimination conditions in EClusUCB is more aggressive than that in UCB-Improved. With appropriate choices of $\psi$, $\rho_a$ and $\rho_s$, we can achieve aggressive elimination even when the gaps $\Delta_i$ are small and $K$ is large. Also we use different exploration regulatory factor than \citet{liu2016modification} and we come up with a cumulative regret bound whereas \citet{liu2016modification} only gives simple regret bound for the CCB algorithm. 
%
%
